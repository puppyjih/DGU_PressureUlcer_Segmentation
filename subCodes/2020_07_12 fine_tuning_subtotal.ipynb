{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2020/07/12 fine_tuning_subtotal.ipynb","provenance":[{"file_id":"1m1VQutXzDVPH4eCd5NC27WzdB7sq71mV","timestamp":1594607462198},{"file_id":"1kOIDLFzUqtIttm4KobRCfd8rEWno2jVz","timestamp":1594560273501},{"file_id":"1VLbG8somqFvPcuuYRm4QAakdUxIKkSmD","timestamp":1594342613418},{"file_id":"1oxY_QwvinIy8tpdXeM0xptFJm0e2ITk-","timestamp":1594321446782}],"collapsed_sections":[],"mount_file_id":"1B8bckoY0F6GJDCMUxUqQg68lIgR2CEvR","authorship_tag":"ABX9TyNoTE9m4T3o6si6/4eeSV31"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"s44k1X57Yicj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1594778781862,"user_tz":-540,"elapsed":7769,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"04d8227a-1dfa-4e8c-e047-015ec07c4ddb"},"source":["%tensorflow_version 1.x\n","from keras.models import Model, Sequential\n","from keras.layers import Activation, Dense, BatchNormalization, concatenate, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n","from keras.callbacks import EarlyStopping\n","from keras.layers.core import SpatialDropout2D\n","from keras import backend as K\n","from keras.optimizers import Adam\n","import keras\n","from keras.models import load_model\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import glob\n","import PIL\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","%matplotlib inline\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from warnings import filterwarnings\n","\n","filterwarnings('ignore')\n","np.random.seed(101)\n","\n","import re\n","numbers = re.compile(r'(\\d+)')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dZrn-98ZYlEf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594778781862,"user_tz":-540,"elapsed":7765,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["def numericalSort(value):\n","    parts = numbers.split(value)\n","    parts[1::2] = map(int, parts[1::2])\n","    return parts\n","    \n","def resizeX(filename, size = (224,224)):\n","    im = Image.open(filename)\n","    im_resized = im.resize(size)\n","    return (im_resized)\n","\n","def resizeY(filename, size = (224,224)):\n","    im = Image.open(filename)\n","    im_resized = im.resize(size).convert('1')\n","    return (im_resized)\n","\n","def jaccard_distance(y_true, y_pred, smooth=100):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return (1 - jac)\n","\n","def iou(y_true, y_pred, smooth = 100):\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return jac\n","\n","def dice_coe(y_true, y_pred, smooth = 100):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def precision(y_true, y_pred):\n","    '''Calculates the precision, a metric for multi-label classification of\n","    how many selected items are relevant.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def recall(y_true, y_pred):\n","    '''Calculates the recall, a metric for multi-label classification of\n","    how many relevant items are selected.\n","    '''\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def accuracy(y_true, y_pred):\n","    '''Calculates the mean accuracy rate across all predictions for binary\n","    classification problems.\n","    '''\n","    return K.mean(K.equal(y_true, K.round(y_pred)))\n","\n","def random_rotation(x_image, y_image):\n","    rows_x,cols_x, chl_x = x_image.shape\n","    rows_y,cols_y = y_image.shape\n","    rand_num = np.random.randint(-40,40)\n","    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n","    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n","    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n","    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n","    return x_image, y_image.astype('int')\n","\n","def horizontal_flip(x_image, y_image):\n","    x_image = cv2.flip(x_image, 1)\n","    y_image = cv2.flip(y_image.astype('float32'), 1)\n","    return x_image, y_image.astype('int')\n","\n","def img_augmentation(x_train, y_train):\n","    x_rotat = []\n","    y_rotat = []\n","    x_flip = []\n","    y_flip = []\n","    for idx in range(len(x_train)):\n","        x,y = random_rotation(x_train[idx], y_train[idx])\n","        x_rotat.append(x)\n","        y_rotat.append(y)\n","        x,y = random_rotation(x_train[idx], y_train[idx])\n","        x_rotat.append(x)\n","        y_rotat.append(y)\n","        x,y = random_rotation(x_train[idx], y_train[idx])\n","        x_rotat.append(x)\n","        y_rotat.append(y)\n","        x,y = random_rotation(x_train[idx], y_train[idx])\n","        x_rotat.append(x)\n","        y_rotat.append(y)\n","        x,y = horizontal_flip(x_train[idx], y_train[idx])\n","        x_flip.append(x)\n","        y_flip.append(y)\n","    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip)\n","\n","def double_conv_layer(x, size, dropout=0.40, batch_norm=True):\n","    if K.common.image_dim_ordering() == 'th':\n","        axis = 1\n","    else:\n","        axis = 3\n","    conv = Conv2D(size, (3, 3), padding='same')(x)\n","    if batch_norm is True:\n","        conv = BatchNormalization(axis=axis)(conv)\n","    conv = Activation('relu')(conv)\n","    conv = Conv2D(size, (3, 3), padding='same')(conv)\n","    if batch_norm is True:\n","        conv = BatchNormalization(axis=axis)(conv)\n","    conv = Activation('relu')(conv)\n","    if dropout > 0:\n","        conv = SpatialDropout2D(dropout)(conv)\n","    return conv\n","\n","\n","def UNET_224(epochs_num, savename, x_train, y_train, x_val, y_val, learningRate = 0.003):\n","    dropout_val=0.50\n","    if K.common.image_dim_ordering() == 'th':\n","        inputs = Input((INPUT_CHANNELS, 224, 224))\n","        axis = 1\n","    else:\n","        inputs = Input((224, 224, INPUT_CHANNELS))\n","        axis = 3\n","    filters = 32\n","\n","    conv_224 = double_conv_layer(inputs, filters)\n","    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n","\n","    conv_112 = double_conv_layer(pool_112, 2*filters)\n","    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n","\n","    conv_56 = double_conv_layer(pool_56, 4*filters)\n","    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n","\n","    conv_28 = double_conv_layer(pool_28, 8*filters)\n","    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n","\n","    conv_14 = double_conv_layer(pool_14, 16*filters)\n","    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n","\n","    conv_7 = double_conv_layer(pool_7, 32*filters)\n","\n","    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n","    up_conv_14 = double_conv_layer(up_14, 16*filters)\n","\n","    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n","    up_conv_28 = double_conv_layer(up_28, 8*filters)\n","\n","    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n","    up_conv_56 = double_conv_layer(up_56, 4*filters)\n","\n","    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n","    up_conv_112 = double_conv_layer(up_112, 2*filters)\n","\n","    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n","    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n","\n","    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n","    conv_final = Activation('sigmoid')(conv_final)\n","    pred = Reshape((224,224))(conv_final)\n","    # model = load_model('/content/drive/My Drive/models/pre_100_epoch.h5' ,custom_objects = {'iou' : iou, 'dice_coe' : dice_coe, 'precision' : precision, 'recall' : recall, 'accuracy' : accuracy, 'jaccard_distance' : jaccard_distance})\n","    # model = load_model('/content/drive/My Drive/models/pre_100_epoch.h5')\n","    model = Model(inputs, pred, name=\"UNET_224\")\n","    model.compile(optimizer= Adam(lr = learningRate), loss= [jaccard_distance]\n","                  , metrics=[iou, dice_coe, precision, recall, accuracy])\n","    model.summary()\n","    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 3,validation_data=(x_val, y_val), verbose=1)\n","    model.save(savename)\n","    return model, hist\n","\n","def enhance(img, filename):\n","    model.load_weights('/content/drive/My Drive/models/' + filename)\n","    sub = (model.predict(img.reshape(1,224,224,3))).flatten()\n","\n","    # for i in range(len(sub)):\n","    #     if sub[i] <= 0.165:\n","    #         sub[i] = 0\n","    #     elif sub[i] <= 0.97:\n","    #         sub[i] = 1\n","    #     else:\n","    #         sub[i] = 2\n","    return sub"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5G_VmALs9km","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594778782745,"user_tz":-540,"elapsed":8646,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["X_train_ph2_resized = []\n","Y_train_ph2_resized = []\n","X_test_ph2_resized = []\n","Y_test_ph2_resized = []"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMNBwb5QwEBA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1594779149033,"user_tz":-540,"elapsed":374925,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"d535c525-2729-456b-a839-85c9bb3d04b2"},"source":["filelist_trainx = sorted(glob.glob('/content/drive/My Drive/input/trainX_total/*.jpg'), key=numericalSort)\n","X_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainx])\n","\n","for i in range(len(filelist_trainx)):\n","    X_train_ph2_resized.append(resizeX(filelist_trainx[i]))\n","\n","print(len(filelist_trainx))\n","\n","del(X_train)\n","del(filelist_trainx)\n","\n","x_train = np.array([np.array(img) for img in X_train_ph2_resized])\n","\n","del(X_train_ph2_resized)\n","\n","x_train.shape"],"execution_count":4,"outputs":[{"output_type":"stream","text":["164\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(164, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"k5JC2bYm-lNU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1594779317428,"user_tz":-540,"elapsed":543316,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"3a0da8c3-c061-4827-bbbc-b0a3165188c0"},"source":["filelist_trainy = sorted(glob.glob('/content/drive/My Drive/input/trainY_total/*.jpg'), key=numericalSort)\n","Y_train = np.array([np.array(Image.open(fname)) for fname in filelist_trainy])\n","\n","for i in range(len(filelist_trainy)):\n","    Y_train_ph2_resized.append(resizeY(filelist_trainy[i]))\n","\n","print(len(filelist_trainy))\n","\n","\n","del(Y_train)\n","del(filelist_trainy)\n","\n","y_train = np.array([np.array(img) for img in Y_train_ph2_resized])\n","\n","del(Y_train_ph2_resized)\n","\n","y_train.shape"],"execution_count":5,"outputs":[{"output_type":"stream","text":["164\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(164, 224, 224)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Nw1srQfm-lfS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594779371188,"user_tz":-540,"elapsed":597073,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["filelist_testX = sorted(glob.glob('/content/drive/My Drive/input/testX_notWater/*.jpg'), key=numericalSort)\n","x_test = np.array([np.array(Image.open(fname)) for fname in filelist_testX])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISrEWhqF-lx-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594779392733,"user_tz":-540,"elapsed":618616,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["filelist_testY = sorted(glob.glob('/content/drive/My Drive/input/testY/*.jpg'), key=numericalSort)\n","y_test = np.array([np.array(Image.open(fname)) for fname in filelist_testY])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Uy1DKu5wFQ1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594779410593,"user_tz":-540,"elapsed":636474,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["for i in range(len(filelist_testX)):\n","    X_test_ph2_resized.append(resizeX(filelist_testX[i]))\n","    Y_test_ph2_resized.append(resizeY(filelist_testY[i]))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtHf2iiNZVmT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1594779411799,"user_tz":-540,"elapsed":637675,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"ba09b061-1d67-4662-d877-17e342f54739"},"source":["del(x_test)\n","del(y_test)\n","\n","x_test = np.array([np.array(img) for img in X_test_ph2_resized])\n","y_test = np.array([np.array(img) for img in Y_test_ph2_resized])\n","\n","# x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.25, random_state = 101)\n","x_rotated, y_rotated, x_flipped, y_flipped = img_augmentation(x_train, y_train)\n","\n","x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n","y_train_full = np.concatenate([y_train, y_rotated, y_flipped])\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)\n","\n","print(\"Length of the Training Set   : {}\".format(len(x_train)))\n","print(\"Length of the Test Set       : {}\".format(len(x_test)))\n","print(\"Length of the Validation Set : {}\".format(len(x_val)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Length of the Training Set   : 787\n","Length of the Test Set       : 20\n","Length of the Validation Set : 197\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PGbNjmLSRH3G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594779544831,"user_tz":-540,"elapsed":900,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"3c86d36d-75fd-4bd5-c297-4ffce0297bf6"},"source":["x_train.shape, y_train.shape\n"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((787, 224, 224, 3), (787, 224, 224))"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"LyD03VKIaGFW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594779529288,"user_tz":-540,"elapsed":32020,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}},"outputId":"6a0a3419-4192-4768-e773-57b938df3112"},"source":["# Number of image channels (for example 3 in case of RGB, or 1 for grayscale images)\n","INPUT_CHANNELS = 3\n","# Number of output masks (1 in case you predict only one type of objects)\n","OUTPUT_MASK_CHANNELS = 1\n","# Pretrained weights\n","\n","# iou, dice_coe, precision, recall, accuracy\n","# callback_list =[ keras.callbacks.ModelCheckpoint( filepath = '/content/drive/My Drive/models/pre_100_epoch.h5',monitor = 'val_loss',save_best_only=True )]\n","\n","x_train.shape\n","y_train.shape\n","model, hist = UNET_224(100, '/content/drive/My Drive/models/20200713_subtotal_100_epoch.h5', x_train, y_train, x_val, y_val, 0.0003)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"UNET_224\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 224, 224, 32) 896         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 224, 224, 32) 128         conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 224, 224, 32) 0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 224, 224, 32) 9248        activation_24[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 224, 224, 32) 128         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 224, 224, 32) 0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_12 (SpatialDr (None, 224, 224, 32) 0           activation_25[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 112, 112, 32) 0           spatial_dropout2d_12[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 112, 112, 64) 256         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 112, 112, 64) 0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 112, 112, 64) 36928       activation_26[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 112, 112, 64) 256         conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 112, 112, 64) 0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_13 (SpatialDr (None, 112, 112, 64) 0           activation_27[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 56, 56, 64)   0           spatial_dropout2d_13[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 56, 56, 128)  73856       max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 56, 56, 128)  512         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 56, 56, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 56, 56, 128)  147584      activation_28[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 56, 56, 128)  512         conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 56, 56, 128)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_14 (SpatialDr (None, 56, 56, 128)  0           activation_29[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 28, 28, 128)  0           spatial_dropout2d_14[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 28, 28, 256)  295168      max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 28, 28, 256)  1024        conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 28, 28, 256)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 28, 28, 256)  590080      activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 28, 28, 256)  1024        conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 28, 28, 256)  0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_15 (SpatialDr (None, 28, 28, 256)  0           activation_31[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_9 (MaxPooling2D)  (None, 14, 14, 256)  0           spatial_dropout2d_15[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 14, 14, 512)  1180160     max_pooling2d_9[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 14, 14, 512)  2048        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 14, 14, 512)  0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 14, 14, 512)  2359808     activation_32[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 14, 14, 512)  2048        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 14, 14, 512)  0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_16 (SpatialDr (None, 14, 14, 512)  0           activation_33[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 512)    0           spatial_dropout2d_16[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 7, 7, 1024)   4719616     max_pooling2d_10[0][0]           \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 7, 7, 1024)   4096        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 7, 7, 1024)   9438208     activation_34[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 7, 7, 1024)   4096        conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 7, 7, 1024)   0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_17 (SpatialDr (None, 7, 7, 1024)   0           activation_35[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d_6 (UpSampling2D)  (None, 14, 14, 1024) 0           spatial_dropout2d_17[0][0]       \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 14, 14, 1536) 0           up_sampling2d_6[0][0]            \n","                                                                 spatial_dropout2d_16[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 14, 14, 512)  7078400     concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 14, 14, 512)  2048        conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 14, 14, 512)  0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 14, 14, 512)  2359808     activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 14, 14, 512)  2048        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 14, 14, 512)  0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_18 (SpatialDr (None, 14, 14, 512)  0           activation_37[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d_7 (UpSampling2D)  (None, 28, 28, 512)  0           spatial_dropout2d_18[0][0]       \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_7[0][0]            \n","                                                                 spatial_dropout2d_15[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 28, 28, 256)  1769728     concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 28, 28, 256)  1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 28, 28, 256)  0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_39 (Conv2D)              (None, 28, 28, 256)  590080      activation_38[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 28, 28, 256)  1024        conv2d_39[0][0]                  \n","__________________________________________________________________________________________________\n","activation_39 (Activation)      (None, 28, 28, 256)  0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_19 (SpatialDr (None, 28, 28, 256)  0           activation_39[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d_8 (UpSampling2D)  (None, 56, 56, 256)  0           spatial_dropout2d_19[0][0]       \n","__________________________________________________________________________________________________\n","concatenate_8 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_8[0][0]            \n","                                                                 spatial_dropout2d_14[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_40 (Conv2D)              (None, 56, 56, 128)  442496      concatenate_8[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 56, 56, 128)  512         conv2d_40[0][0]                  \n","__________________________________________________________________________________________________\n","activation_40 (Activation)      (None, 56, 56, 128)  0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_41 (Conv2D)              (None, 56, 56, 128)  147584      activation_40[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_40 (BatchNo (None, 56, 56, 128)  512         conv2d_41[0][0]                  \n","__________________________________________________________________________________________________\n","activation_41 (Activation)      (None, 56, 56, 128)  0           batch_normalization_40[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_20 (SpatialDr (None, 56, 56, 128)  0           activation_41[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d_9 (UpSampling2D)  (None, 112, 112, 128 0           spatial_dropout2d_20[0][0]       \n","__________________________________________________________________________________________________\n","concatenate_9 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_9[0][0]            \n","                                                                 spatial_dropout2d_13[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_42 (Conv2D)              (None, 112, 112, 64) 110656      concatenate_9[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_41 (BatchNo (None, 112, 112, 64) 256         conv2d_42[0][0]                  \n","__________________________________________________________________________________________________\n","activation_42 (Activation)      (None, 112, 112, 64) 0           batch_normalization_41[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_43 (Conv2D)              (None, 112, 112, 64) 36928       activation_42[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_42 (BatchNo (None, 112, 112, 64) 256         conv2d_43[0][0]                  \n","__________________________________________________________________________________________________\n","activation_43 (Activation)      (None, 112, 112, 64) 0           batch_normalization_42[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_21 (SpatialDr (None, 112, 112, 64) 0           activation_43[0][0]              \n","__________________________________________________________________________________________________\n","up_sampling2d_10 (UpSampling2D) (None, 224, 224, 64) 0           spatial_dropout2d_21[0][0]       \n","__________________________________________________________________________________________________\n","concatenate_10 (Concatenate)    (None, 224, 224, 96) 0           up_sampling2d_10[0][0]           \n","                                                                 spatial_dropout2d_12[0][0]       \n","__________________________________________________________________________________________________\n","conv2d_44 (Conv2D)              (None, 224, 224, 32) 27680       concatenate_10[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_43 (BatchNo (None, 224, 224, 32) 128         conv2d_44[0][0]                  \n","__________________________________________________________________________________________________\n","activation_44 (Activation)      (None, 224, 224, 32) 0           batch_normalization_43[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_45 (Conv2D)              (None, 224, 224, 32) 9248        activation_44[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_44 (BatchNo (None, 224, 224, 32) 128         conv2d_45[0][0]                  \n","__________________________________________________________________________________________________\n","activation_45 (Activation)      (None, 224, 224, 32) 0           batch_normalization_44[0][0]     \n","__________________________________________________________________________________________________\n","spatial_dropout2d_22 (SpatialDr (None, 224, 224, 32) 0           activation_45[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_46 (Conv2D)              (None, 224, 224, 1)  33          spatial_dropout2d_22[0][0]       \n","__________________________________________________________________________________________________\n","activation_46 (Activation)      (None, 224, 224, 1)  0           conv2d_46[0][0]                  \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 224, 224)     0           activation_46[0][0]              \n","==================================================================================================\n","Total params: 31,466,753\n","Trainable params: 31,454,721\n","Non-trainable params: 12,032\n","__________________________________________________________________________________________________\n","Train on 787 samples, validate on 197 samples\n","Epoch 1/100\n","165/787 [=====>........................] - ETA: 1:09 - loss: 0.2733 - iou: 0.7267 - dice_coe: 0.2056 - precision: 0.2287 - recall: 0.6682 - accuracy: 0.7372"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b8101b6e6011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNET_224\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/models/20200713_subtotal_100_epoch.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-7e16544f7037>\u001b[0m in \u001b[0;36mUNET_224\u001b[0;34m(epochs_num, savename, x_train, y_train, x_val, y_val, learningRate)\u001b[0m\n\u001b[1;32m    163\u001b[0m                   , metrics=[iou, dice_coe, precision, recall, accuracy])\n\u001b[1;32m    164\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepochs_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"GK68vDN-fXlh","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594779495848,"user_tz":-540,"elapsed":721715,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["model.load_weights('/content/drive/My Drive/models/20200713_subtotal_100_epoch.h5')\n","\n","print('\\n~~~~~~~~~~~~~~~Stats after 100 epoch~~~~~~~~~~~~~~~~~~~')\n","print('\\n-------------On Train Set--------------------------\\n')\n","res = model.evaluate(x_train, y_train, batch_size= 18)\n","print('________________________')\n","print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n","print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n","print('Precision: |   {:.2f}  |'.format(res[3]*100))\n","print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n","print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n","print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n","print('________________________')\n","print('\\n-------------On Test  Set--------------------------\\n')\n","res = model.evaluate(x_test, y_test, batch_size= 18)\n","print('________________________')\n","print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n","print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n","print('Precision: |   {:.2f}  |'.format(res[3]*100))\n","print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n","print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n","print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n","print('________________________')\n","print('\\n-------------On validation Set---------------------\\n')\n","res = model.evaluate(x_val, y_val, batch_size= 18)\n","print('________________________')\n","print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n","print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n","print('Precision: |   {:.2f}  |'.format(res[3]*100))\n","print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n","print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n","print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n","print('________________________')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShjkfJJSfnx4","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594779495850,"user_tz":-540,"elapsed":721712,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["for i in range(len(x_train)):\n","  plt.figure(figsize=(12,4))\n","  plt.subplot(1,3,1)\n","  plt.title('Origin Image')\n","  plt.imshow(x_train[i])\n","  plt.subplot(1,3,2)\n","  plt.title('Ground Truth')\n","  plt.imshow(y_train[i], plt.cm.binary_r)\n","  plt.subplot(1,3,3)\n","  plt.title('Predicted')\n","  plt.imshow(enhance(x_train[i], '20200713_subtotal_100_epoch.h5').reshape(224,224), plt.cm.binary_r)\n","  # plt.subplot(3,2,5)\n","  # plt.title('Ground_Truth_out')\n","  # plt.imshow(Y_train_out[i],plt.cm.binary_r)\n","  # plt.subplot(3,2,6)\n","  # plt.title('Predicted_out')\n","  # plt.imshow(enhance_out(X_train[i]).reshape(224,224),plt.cm.binary_r)\n","  plt.savefig('/content/drive/My Drive/results/total/20200713_subtotal_train/' + str(i) + '.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KiFg2t0RCGA","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1594779495850,"user_tz":-540,"elapsed":721708,"user":{"displayName":"황종익","photoUrl":"","userId":"12880745926777787394"}}},"source":["sum_iou = 0\n","sum_dice = 0\n","sum_acc = 0\n","\n","for i in range(len(x_test)):\n","  pdata = (model.predict(x_test[i].reshape(1,224,224,3))).reshape(1,224,224,1)\n","  # print(pdata.shape)\n","  # ensemble = np.zeros((1,224,224,1))\n","  # print(pdata.shape)\n","  # for j in range(224) :\n","  #       for k in range(224) :\n","  #           ensemble[i][j][[k]0] = pdata[j][k][0]\n","  ensemble = pdata\n","  ensemble = ensemble * 255\n","  ensemble = ensemble.squeeze(axis=0)\n","  # print(ensemble.shape)\n","  ensemble = ensemble.astype(np.uint8)\n","  ret3, th3 = cv2.threshold(ensemble, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n","\n","\n","  th3 = th3/255\n","  # print(th3.shape)\n","  # print(y_test[i].shape)\n","  A = 1\n","  cnt = 1\n","  B = 1\n","  C = 0\n","  top = 0\n","  bottom = 0\n","\n","  for j in range(224) :\n","      for k in range(224) : \n","          A += y_test[i][j][k]\n","          B += th3[j][k]     \n","          if y_test[i][j][k] == th3[j][k] : # 00, 11 인 경우\n","              cnt += th3[j][k]\n","              top += th3[j][k]\n","              bottom += th3[j][k]\n","              C+=1\n","          else : # 01 10 인 경우\n","              bottom += 1\n","  \n","  dice = cnt*2 / (A+B) \n","  iou = top / bottom\n","  acc = C / (224*224)\n","  \n","  sum_acc += acc\n","  sum_iou +=iou\n","  sum_dice += dice\n","  print(i , '번째 사진의 정확도 ')\n","  print('iou : ' , iou)\n","  print('dice : ' , dice)\n","  print('acc : ', acc)\n","  print()\n","  inputStr = 'Image ' + str(i) + '\\n' + 'iou : ' + str(iou) + '\\ndice : ' + str(dice) + '\\nacc : ' + str(acc) + '\\n'\n","  # print(inputStr)\n","\n","\n","  plt.figure(figsize=(12,6))\n","  ax1 = plt.subplot(2,4,5)\n","  plt.title('Origin Image')\n","  plt.imshow(x_test[i])\n","  plt.subplot(2,4,6)\n","  plt.title('Ground Truth')\n","  plt.imshow(y_test[i], plt.cm.binary_r)\n","  plt.subplot(2,4,7)\n","  plt.title('Predicted')\n","  plt.imshow(enhance(x_test[i], '20200713_subtotal_100_epoch.h5').reshape(224,224), plt.cm.binary_r)\n","  plt.subplot(2,4,8)\n","  plt.imshow(th3.squeeze(), plt.cm.binary_r)\n","  plt.title('binarization')\n","  plt.axis('off')\n","  ax1.text(0, 1.1, s = inputStr, size=12,transform=ax1.transAxes)\n","  plt.savefig('/content/drive/My Drive/results/total/20200713_subtotal_test/' + str(i) + '.jpg')\n","\n","print('acc : ',sum_acc/20)\n","print('iou : ',sum_iou/20)\n","print('dice : ',sum_dice/20)"],"execution_count":null,"outputs":[]}]}